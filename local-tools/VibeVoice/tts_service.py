"""
VibeVoice è½»é‡çº§ Web æœåŠ¡
åŸºäº FastAPIï¼Œå»é™¤ Gradio ä¾èµ–
"""

import argparse
import json
import tempfile
import time
from pathlib import Path
from typing import List, Dict, Any
import numpy as np
import soundfile as sf
import torch
from fastapi import FastAPI, HTTPException
from fastapi.responses import FileResponse, JSONResponse
from pydantic import BaseModel
import uvicorn

from vibevoice.modular.modeling_vibevoice_inference import VibeVoiceForConditionalGenerationInference
from vibevoice.processor.vibevoice_processor import VibeVoiceProcessor
from transformers import set_seed


class TTSRequest(BaseModel):
    text: str
    speakers: List[str] = ["Alice", "Bob"]
    cfg_scale: float = 1.3


class TTSResponse(BaseModel):
    success: bool
    message: str
    audio_file: str = None
    duration: float = None


class VibeVoiceService:
    def __init__(self, model_path: str, device: str = "cuda"):
        self.model_path = model_path
        self.device = device
        self.model = None
        self.processor = None
        self.model_loaded = False
        
    def load_model(self):
        """åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨"""
        print(f"ğŸ”„ Loading model from {self.model_path}")
        
        # è®¾å¤‡é…ç½®
        if self.device == "cuda" and torch.cuda.is_available():
            load_dtype = torch.bfloat16
            attn_impl = "sdpa"  # ä½¿ç”¨ sdpa é¿å… FlashAttention2 ä¾èµ–
        else:
            self.device = "cpu"
            load_dtype = torch.float32
            attn_impl = "sdpa"
            
        print(f"ğŸ“± Device: {self.device}, dtype: {load_dtype}")
        
        # åŠ è½½å¤„ç†å™¨
        self.processor = VibeVoiceProcessor.from_pretrained(self.model_path)
        
        # åŠ è½½æ¨¡å‹
        self.model = VibeVoiceForConditionalGenerationInference.from_pretrained(
            self.model_path,
            torch_dtype=load_dtype,
            device_map=self.device if self.device != "cpu" else None,
            attn_implementation=attn_impl,
        )
        
        if self.device == "cpu":
            self.model = self.model.to("cpu")
            
        self.model.eval()
        
        # é…ç½®æ¨ç†æ­¥æ•°
        self.model.set_ddpm_inference_steps(num_steps=5)
        
        self.model_loaded = True
        print("âœ… Model loaded successfully")
        
    def synthesize_speech(self, text: str, speakers: List[str], cfg_scale: float = 1.3) -> str:
        """åˆæˆè¯­éŸ³å¹¶è¿”å›ä¸´æ—¶æ–‡ä»¶è·¯å¾„"""
        if not self.model_loaded:
            raise HTTPException(status_code=400, detail="Model not loaded")
            
        start_time = time.time()
        
        # æ ¼å¼åŒ–è„šæœ¬
        lines = text.strip().split('\n')
        formatted_lines = []
        
        for i, line in enumerate(lines):
            if line.strip():
                speaker_idx = i % len(speakers)
                if not line.startswith('Speaker'):
                    formatted_lines.append(f"Speaker {speaker_idx}: {line.strip()}")
                else:
                    formatted_lines.append(line.strip())
                    
        formatted_script = '\n'.join(formatted_lines)
        
        # å‡†å¤‡è¯­éŸ³æ ·æœ¬ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥åŠ è½½çœŸå®çš„è¯­éŸ³æ–‡ä»¶ï¼‰
        # ä¸ºæ¼”ç¤ºç›®çš„åˆ›å»ºè™šæ‹Ÿè¯­éŸ³æ ·æœ¬
        voice_samples = []
        for _ in speakers:
            # åˆ›å»ºç®€å•çš„å™ªå£°ä½œä¸ºè¯­éŸ³æ ·æœ¬å ä½ç¬¦
            dummy_sample = np.random.randn(24000).astype(np.float32) * 0.1
            voice_samples.append(dummy_sample)
        
        # å¤„ç†è¾“å…¥
        inputs = self.processor(
            text=[formatted_script],
            voice_samples=[voice_samples],
            padding=True,
            return_tensors="pt",
            return_attention_mask=True,
        )
        
        # ç§»åŠ¨åˆ°è®¾å¤‡
        if self.device != "cpu":
            for k, v in inputs.items():
                if torch.is_tensor(v):
                    inputs[k] = v.to(self.device)
        
        # ç”ŸæˆéŸ³é¢‘
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=None,
                cfg_scale=cfg_scale,
                tokenizer=self.processor.tokenizer,
                generation_config={'do_sample': False},
                verbose=False,
            )
        
        # è½¬æ¢ä¸ºéŸ³é¢‘æ•°æ®
        # VibeVoice è¾“å‡ºé€šå¸¸æ˜¯ VibeVoiceGenerationOutput å¯¹è±¡
        if hasattr(outputs, 'speech_outputs'):
            # å…³é”®ï¼éŸ³é¢‘æ•°æ®åœ¨ speech_outputs ä¸­ï¼Œä¸æ˜¯ sequencesï¼
            audio_tensor = outputs.speech_outputs[0]  # å–ç¬¬ä¸€ä¸ªbatch
        elif hasattr(outputs, 'audio'):
            # å¦‚æœè¾“å‡ºæœ‰ audio å±æ€§
            audio_tensor = outputs.audio
        elif torch.is_tensor(outputs):
            # å¦‚æœç›´æ¥æ˜¯tensor
            audio_tensor = outputs
        else:
            # å°è¯•è·å–ç¬¬ä¸€ä¸ªå…ƒç´ 
            if hasattr(outputs, '__getitem__'):
                audio_tensor = outputs[0]
            else:
                raise ValueError(f"Unsupported output type: {type(outputs)}")
        
        # è½¬æ¢tensorä¸ºnumpy
        if torch.is_tensor(audio_tensor):
            if audio_tensor.dtype == torch.bfloat16:
                audio_tensor = audio_tensor.float()
            audio_data = audio_tensor.cpu().numpy().astype(np.float32)
        else:
            audio_data = np.array(audio_tensor, dtype=np.float32)
            
        # ç¡®ä¿æ˜¯1Dæ•°ç»„
        if len(audio_data.shape) > 1:
            audio_data = audio_data.squeeze()
            
        # ä¿å­˜ä¸ºä¸´æ—¶WAVæ–‡ä»¶
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
        sf.write(temp_file.name, audio_data, 24000)
        
        generation_time = time.time() - start_time
        duration = len(audio_data) / 24000
        
        print(f"ğŸµ Generated {duration:.2f}s audio in {generation_time:.2f}s")
        
        return temp_file.name, duration


# å…¨å±€æœåŠ¡å®ä¾‹
tts_service = None


def create_app() -> FastAPI:
    app = FastAPI(
        title="VibeVoice TTS Service",
        description="è½»é‡çº§ VibeVoice æ–‡æœ¬è½¬è¯­éŸ³æœåŠ¡",
        version="1.0.0"
    )
    
    @app.get("/")
    async def root():
        return {"message": "VibeVoice TTS Service", "status": "running"}
    
    @app.post("/tts", response_model=TTSResponse)
    async def text_to_speech(request: TTSRequest):
        """æ–‡æœ¬è½¬è¯­éŸ³æ¥å£"""
        global tts_service
        
        if tts_service is None:
            raise HTTPException(status_code=503, detail="TTS service not initialized")
            
        try:
            audio_file, duration = tts_service.synthesize_speech(
                text=request.text,
                speakers=request.speakers,
                cfg_scale=request.cfg_scale
            )
            
            return TTSResponse(
                success=True,
                message="Speech synthesis completed",
                audio_file=audio_file,
                duration=duration
            )
            
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Synthesis failed: {str(e)}")
    
    @app.get("/audio/{filename}")
    async def get_audio(filename: str):
        """è·å–ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶"""
        file_path = Path(filename)
        if file_path.exists():
            return FileResponse(file_path, media_type="audio/wav")
        else:
            raise HTTPException(status_code=404, detail="Audio file not found")
    
    @app.get("/health")
    async def health_check():
        """å¥åº·æ£€æŸ¥"""
        global tts_service
        return {
            "status": "healthy" if tts_service and tts_service.model_loaded else "not ready",
            "model_loaded": tts_service.model_loaded if tts_service else False
        }
    
    return app


def main():
    global tts_service
    
    parser = argparse.ArgumentParser(description="VibeVoice TTS Web Service")
    parser.add_argument(
        "--model_path",
        type=str,
        default="microsoft/VibeVoice-1.5B",
        help="Path to VibeVoice model"
    )
    parser.add_argument(
        "--device",
        type=str,
        default="cuda" if torch.cuda.is_available() else "cpu",
        help="Device for inference"
    )
    parser.add_argument(
        "--host",
        type=str,
        default="127.0.0.1",
        help="Host to bind to"
    )
    parser.add_argument(
        "--port",
        type=int,
        default=8000,
        help="Port to listen on"
    )
    
    args = parser.parse_args()
    
    set_seed(42)
    
    print("ğŸ™ï¸ VibeVoice TTS Web Service")
    print("============================")
    
    # åˆå§‹åŒ–æœåŠ¡
    tts_service = VibeVoiceService(args.model_path, args.device)
    tts_service.load_model()
    
    # åˆ›å»ºåº”ç”¨
    app = create_app()
    
    print(f"ğŸš€ Starting server on {args.host}:{args.port}")
    print(f"ğŸ“– APIæ–‡æ¡£: http://{args.host}:{args.port}/docs")
    print(f"ğŸ§ª æµ‹è¯•æ¥å£: http://{args.host}:{args.port}/health")
    
    # å¯åŠ¨æœåŠ¡å™¨
    uvicorn.run(
        app,
        host=args.host,
        port=args.port,
        log_level="info"
    )


if __name__ == "__main__":
    main()